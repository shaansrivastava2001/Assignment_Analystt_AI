# -*- coding: utf-8 -*-
"""Assignment_AnalysttAI_Part2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1GAvJga3C4Zt0v8chnFq_lwXq-rJNgxYI
"""

from google.colab import files

uploaded = files.upload()

import requests
from bs4 import BeautifulSoup

url_file = open('page_urls.txt','r')
headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2228.0 Safari/537.36'
}

c = 1
with open('all_products_urls.txt', 'w') as f:
  for i in url_file:
    url = i
    print("Link",c,"scanned!!")
    c+=1
    page = requests.get(url, headers = headers)

    htmlContent = page.content
    soup = BeautifulSoup(htmlContent,'html.parser')

    links = soup.find_all('a',{'class':'a-link-normal s-underline-text s-underline-link-text s-link-style'})
    for i in links:
      if(i.get('href')[-7:-2]=='Revie'):
        url = 'https://www.amazon.in'+i.get('href')[:-16]
        f.write(url)
        f.write('\n')

def product_name(soup):
  title = soup.find("span", attrs={"id":'productTitle'})
  if title is not None:
    ret = title.string.strip()
    return ret

  return ""

def product_asin(soup):
  item = soup.find("div", attrs={"id":'detailBullets_feature_div'})
  if item is not None:
    spans = item.find_all(recursive=False)
    asin = ""
    for i in spans:
      temp = i.find_all(recursive=False)
      for j in temp:
        temp2 = j.find_all(recursive=False)
        for k in temp2:
              temp3 = k.find_all(recursive=False)
              if(temp3[0].text.split(':')[0].strip()[:4]=="ASIN"):
                asin = temp3[1].text.strip()

    if len(asin)!=0:
      return asin

    return "NA"

  else:
    return "NA"

def product_manufacturer(soup):
  item = soup.find("div", attrs={"id":'detailBullets_feature_div'})
  manu = ""
  if item is not None:
    manu = ""
    spans = item.find_all(recursive=False)
    for i in spans:
      temp = i.find_all(recursive=False)
      for j in temp:
        temp2 = j.find_all(recursive=False)
        for k in temp2:
              temp3 = k.find_all(recursive=False)
              if(temp3[0].text.split(':')[0].strip()[:12]=="Manufacturer"):
                manu = temp3[1].text.strip()

    if len(manu)==0:
      return "NA"

    return manu

  else:
    return "NA"    


def product_description(soup):
  item = soup.find("div",attrs={"id":'aplus'})
  if item is not None:
    tables = item.find("table")
    if tables is not None:
      headings = tables.find_all("h4")
      desc = ""
      for i in headings:
        desc = desc+i.text.strip()+", "

      return desc[:-2]

    else:
      return "NA"

  else:
    return "NA"

import csv  

header = ['ASIN', 'Manufacturer', 'Description']

file = open('all_products_urls.txt','r')
with open('products_data.csv', 'w') as f:
  c = 0
  for i in file:
    c+=1
    print("Product",c)
    product_url = i
    page = requests.get(product_url, headers = headers)
    htmlContent = page.content
    soup = BeautifulSoup(htmlContent,'html.parser')

    asin = product_asin(soup)
    manu = product_manufacturer(soup)
    desc = product_description(soup)
    data = [asin, manu, desc]
    writer = csv.writer(f)
    if(c==1):
      writer.writerow(header)
    
    writer.writerow(data)

